{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1454         160         21.0     1936            4            7       1970   \n",
       "1455         160         21.0     1894            4            5       1970   \n",
       "1456          20        160.0    20000            5            7       1960   \n",
       "1457          85         62.0    10441            5            5       1992   \n",
       "1458          60         74.0     9627            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0             2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1             1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2             2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3             1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4             2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "...            ...         ...         ...         ...  ...   ...   ...  ...   \n",
       "1454          1970         0.0         0.0         0.0  ...     0     0    1   \n",
       "1455          1970         0.0       252.0         0.0  ...     0     0    1   \n",
       "1456          1996         0.0      1224.0         0.0  ...     0     0    1   \n",
       "1457          1992         0.0       337.0         0.0  ...     0     0    1   \n",
       "1458          1994        94.0       758.0         0.0  ...     0     0    1   \n",
       "\n",
       "      Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0          1        0        0        0       0    1  0  \n",
       "1          1        0        0        0       0    1  0  \n",
       "2          1        0        0        0       0    1  0  \n",
       "3          0        0        0        0       1    0  0  \n",
       "4          1        0        0        0       0    1  0  \n",
       "...      ...      ...      ...      ...     ...  ... ..  \n",
       "1454       1        0        0        0       0    0  0  \n",
       "1455       0        0        0        1       0    0  0  \n",
       "1456       0        0        0        0       1    0  0  \n",
       "1457       1        0        0        0       0    0  0  \n",
       "1458       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1          1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2          2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3          1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4          2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keshav Sharma\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  5.8min\n"
     ]
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:47:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:47:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=1, nthread=1, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, seed=0, silent=True, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_Test.drop(['SalePrice'],axis=1).head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117275.625, 163568.39 , 188306.14 , ..., 181178.69 , 115435.21 ,\n",
       "       236526.36 ], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 175)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 577 samples\n",
      "Epoch 1/1000\n",
      "2304/2304 [==============================] - 2s 1ms/step - loss: 113530.5093 - val_loss: 56624.8765\n",
      "Epoch 2/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 62615.1298 - val_loss: 50444.1900\n",
      "Epoch 3/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 56279.5739 - val_loss: 44504.8296\n",
      "Epoch 4/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 50261.0310 - val_loss: 39335.5723\n",
      "Epoch 5/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 44449.5163 - val_loss: 35396.5539\n",
      "Epoch 6/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 40090.4315 - val_loss: 35178.2237\n",
      "Epoch 7/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 37493.4126 - val_loss: 31983.3301\n",
      "Epoch 8/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 36462.1401 - val_loss: 34241.1639\n",
      "Epoch 9/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 35635.4539 - val_loss: 32087.6040\n",
      "Epoch 10/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 35851.5885 - val_loss: 32125.1113\n",
      "Epoch 11/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 35622.6530 - val_loss: 31914.6602\n",
      "Epoch 12/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 35187.7144 - val_loss: 31882.3983\n",
      "Epoch 13/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 35196.1213 - val_loss: 32342.4395\n",
      "Epoch 14/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 34929.6660 - val_loss: 31565.0875\n",
      "Epoch 15/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 34672.9052 - val_loss: 32177.3833\n",
      "Epoch 16/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 34501.2563 - val_loss: 31293.5959\n",
      "Epoch 17/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 34804.2316 - val_loss: 31182.3204\n",
      "Epoch 18/1000\n",
      "2304/2304 [==============================] - 2s 778us/step - loss: 34455.4584 - val_loss: 31376.9020\n",
      "Epoch 19/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 34377.8071 - val_loss: 31301.4047\n",
      "Epoch 20/1000\n",
      "2304/2304 [==============================] - 1s 477us/step - loss: 34164.2543 - val_loss: 31142.9020\n",
      "Epoch 21/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 34009.0316 - val_loss: 31243.3016\n",
      "Epoch 22/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 33660.4401 - val_loss: 31494.8445\n",
      "Epoch 23/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 33812.4372 - val_loss: 31299.1932\n",
      "Epoch 24/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 33589.9288 - val_loss: 31848.2731\n",
      "Epoch 25/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 33607.1809 - val_loss: 30390.6748\n",
      "Epoch 26/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 33473.9579 - val_loss: 30910.1593\n",
      "Epoch 27/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 33236.2349 - val_loss: 30219.5441\n",
      "Epoch 28/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 33243.2710 - val_loss: 30179.0993\n",
      "Epoch 29/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 32929.2295 - val_loss: 30128.3545\n",
      "Epoch 30/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32963.0511 - val_loss: 30510.0357\n",
      "Epoch 31/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 32787.1626 - val_loss: 29853.5188\n",
      "Epoch 32/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 32766.8486 - val_loss: 30704.6890\n",
      "Epoch 33/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 32790.5330 - val_loss: 30381.5674\n",
      "Epoch 34/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 32740.6885 - val_loss: 29614.6660\n",
      "Epoch 35/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32658.3221 - val_loss: 30323.1913\n",
      "Epoch 36/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 32570.0888 - val_loss: 30407.4534\n",
      "Epoch 37/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32189.7531 - val_loss: 30379.3509\n",
      "Epoch 38/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 32140.4911 - val_loss: 29347.5356\n",
      "Epoch 39/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 31913.3835 - val_loss: 29861.8741\n",
      "Epoch 40/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 32135.0634 - val_loss: 29108.2475\n",
      "Epoch 41/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32026.9856 - val_loss: 29142.3169\n",
      "Epoch 42/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 31792.7488 - val_loss: 29323.2182\n",
      "Epoch 43/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 31622.7127 - val_loss: 29028.4757\n",
      "Epoch 44/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 31769.7568 - val_loss: 29493.1864\n",
      "Epoch 45/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 31732.7656 - val_loss: 29812.4935\n",
      "Epoch 46/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 31434.8387 - val_loss: 28903.6488\n",
      "Epoch 47/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 31234.3539 - val_loss: 28895.0965\n",
      "Epoch 48/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 31151.4855 - val_loss: 28861.3638\n",
      "Epoch 49/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 31274.5573 - val_loss: 29427.3137\n",
      "Epoch 50/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 31510.8220 - val_loss: 28567.3384\n",
      "Epoch 51/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 31460.1977 - val_loss: 28814.4977\n",
      "Epoch 52/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 31085.8429 - val_loss: 28524.2395\n",
      "Epoch 53/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30989.9977 - val_loss: 28568.5788\n",
      "Epoch 54/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 31092.4584 - val_loss: 28378.7455\n",
      "Epoch 55/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 30932.9268 - val_loss: 30094.5473\n",
      "Epoch 56/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30684.4676 - val_loss: 28414.4087\n",
      "Epoch 57/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 30493.6564 - val_loss: 29508.0253\n",
      "Epoch 58/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 30652.6024 - val_loss: 28326.5143\n",
      "Epoch 59/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30778.1669 - val_loss: 28056.4234\n",
      "Epoch 60/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 30424.7307 - val_loss: 28010.0378\n",
      "Epoch 61/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 30072.8579 - val_loss: 28027.6187\n",
      "Epoch 62/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30334.3219 - val_loss: 28459.9857\n",
      "Epoch 63/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30427.8750 - val_loss: 29863.5684\n",
      "Epoch 64/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30285.2018 - val_loss: 28957.1549\n",
      "Epoch 65/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 30310.4877 - val_loss: 28183.0357\n",
      "Epoch 66/1000\n",
      "2304/2304 [==============================] - 1s 405us/step - loss: 30276.2501 - val_loss: 27665.3018\n",
      "Epoch 67/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29832.1718 - val_loss: 27712.5372\n",
      "Epoch 68/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 30272.4041 - val_loss: 27718.7824\n",
      "Epoch 69/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 30113.7119 - val_loss: 28000.3839\n",
      "Epoch 70/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29942.6214 - val_loss: 27786.2428\n",
      "Epoch 71/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 29859.0674 - val_loss: 27215.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29209.5491 - val_loss: 27173.5760\n",
      "Epoch 73/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 29919.4843 - val_loss: 27220.3691\n",
      "Epoch 74/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 29509.6134 - val_loss: 27340.0882\n",
      "Epoch 75/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 29708.4845 - val_loss: 27312.6990\n",
      "Epoch 76/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 29519.9725 - val_loss: 27508.6494\n",
      "Epoch 77/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29357.4566 - val_loss: 26867.6287\n",
      "Epoch 78/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29159.6736 - val_loss: 26893.8640\n",
      "Epoch 79/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 29366.9112 - val_loss: 26603.1912\n",
      "Epoch 80/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 29120.4931 - val_loss: 26661.9235\n",
      "Epoch 81/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 28946.7935 - val_loss: 27871.8099\n",
      "Epoch 82/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 29138.3855 - val_loss: 26531.3914\n",
      "Epoch 83/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 28846.1910 - val_loss: 28481.5947\n",
      "Epoch 84/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29017.1691 - val_loss: 26508.0993\n",
      "Epoch 85/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 28775.6919 - val_loss: 26779.5843\n",
      "Epoch 86/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 29089.2547 - val_loss: 27172.3217\n",
      "Epoch 87/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 28686.1871 - val_loss: 26091.4350\n",
      "Epoch 88/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28698.4660 - val_loss: 26102.4028\n",
      "Epoch 89/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 28699.3697 - val_loss: 26289.4353\n",
      "Epoch 90/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 28489.5871 - val_loss: 27897.5505\n",
      "Epoch 91/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 28665.1914 - val_loss: 25854.9589\n",
      "Epoch 92/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 28285.7090 - val_loss: 25977.9663\n",
      "Epoch 93/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 28285.7983 - val_loss: 25438.4628\n",
      "Epoch 94/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28321.3720 - val_loss: 25585.6818\n",
      "Epoch 95/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 28190.3902 - val_loss: 25334.2817\n",
      "Epoch 96/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 28360.6425 - val_loss: 25095.3392\n",
      "Epoch 97/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 28196.4608 - val_loss: 24977.6499\n",
      "Epoch 98/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 28143.1103 - val_loss: 24957.5144\n",
      "Epoch 99/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 28541.725 - 1s 465us/step - loss: 28404.1788 - val_loss: 25377.6330\n",
      "Epoch 100/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 27923.1122 - val_loss: 25035.9833\n",
      "Epoch 101/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 28224.6294 - val_loss: 24864.9644\n",
      "Epoch 102/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27838.1132 - val_loss: 26435.8536\n",
      "Epoch 103/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 27936.2079 - val_loss: 24885.9012\n",
      "Epoch 104/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 27583.212 - 1s 450us/step - loss: 27619.0787 - val_loss: 24613.4044\n",
      "Epoch 105/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 27628.1560 - val_loss: 24228.4823\n",
      "Epoch 106/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 27878.6943 - val_loss: 24845.3175\n",
      "Epoch 107/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 27493.7438 - val_loss: 24612.2324\n",
      "Epoch 108/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 27134.2120 - val_loss: 25914.3079\n",
      "Epoch 109/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 27448.0619 - val_loss: 23640.7174\n",
      "Epoch 110/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 27225.6602 - val_loss: 24300.4790\n",
      "Epoch 111/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 27457.5783 - val_loss: 23591.0836\n",
      "Epoch 112/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27562.5854 - val_loss: 23601.4916\n",
      "Epoch 113/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 26970.8130 - val_loss: 23496.5879\n",
      "Epoch 114/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 27141.8372 - val_loss: 24716.6597\n",
      "Epoch 115/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 26687.5030 - val_loss: 25936.5065\n",
      "Epoch 116/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 26811.0217 - val_loss: 23067.7963\n",
      "Epoch 117/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 26862.9685 - val_loss: 23789.6916\n",
      "Epoch 118/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 26478.2679 - val_loss: 24595.6749\n",
      "Epoch 119/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 26766.5188 - val_loss: 23377.8840\n",
      "Epoch 120/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 26545.6570 - val_loss: 22453.2940\n",
      "Epoch 121/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 26442.3213 - val_loss: 22567.1628\n",
      "Epoch 122/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 26011.6722 - val_loss: 24087.4123\n",
      "Epoch 123/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 26506.6031 - val_loss: 22453.8540\n",
      "Epoch 124/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 26042.1024 - val_loss: 22348.5490\n",
      "Epoch 125/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 26685.7815 - val_loss: 21968.0753\n",
      "Epoch 126/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 25654.7254 - val_loss: 22398.2175\n",
      "Epoch 127/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 25909.7507 - val_loss: 21961.1548\n",
      "Epoch 128/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 25938.8809 - val_loss: 21437.6150\n",
      "Epoch 129/1000\n",
      "2304/2304 [==============================] - 1s 476us/step - loss: 25268.5747 - val_loss: 21907.7049\n",
      "Epoch 130/1000\n",
      "2304/2304 [==============================] - 1s 470us/step - loss: 25609.2470 - val_loss: 21246.5780\n",
      "Epoch 131/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 25023.4624 - val_loss: 24637.6923\n",
      "Epoch 132/1000\n",
      "2304/2304 [==============================] - 1s 520us/step - loss: 25366.8912 - val_loss: 21211.1705\n",
      "Epoch 133/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 25424.9557 - val_loss: 21021.8191\n",
      "Epoch 134/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 25343.5929 - val_loss: 21586.6650\n",
      "Epoch 135/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 24995.2175 - val_loss: 21105.6569\n",
      "Epoch 136/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 24986.7363 - val_loss: 20605.5033\n",
      "Epoch 137/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 25225.4030 - val_loss: 20552.5941\n",
      "Epoch 138/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 25014.9195 - val_loss: 21813.1205\n",
      "Epoch 139/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 24983.0982 - val_loss: 20684.3204\n",
      "Epoch 140/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 24864.2334 - val_loss: 20245.8430\n",
      "Epoch 141/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 24915.6213 - val_loss: 19954.3808\n",
      "Epoch 142/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 24832.0423 - val_loss: 22799.6597\n",
      "Epoch 143/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 24758.2035 - val_loss: 20148.5544\n",
      "Epoch 144/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 24726.4656 - val_loss: 19816.7254\n",
      "Epoch 145/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24342.4105 - val_loss: 21506.8392\n",
      "Epoch 146/1000\n",
      "2304/2304 [==============================] - 1s 494us/step - loss: 24704.4509 - val_loss: 19672.9874\n",
      "Epoch 147/1000\n",
      "2304/2304 [==============================] - 1s 483us/step - loss: 24873.8309 - val_loss: 19765.3019\n",
      "Epoch 148/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 24126.7666 - val_loss: 21504.0878\n",
      "Epoch 149/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24424.1095 - val_loss: 21462.0763\n",
      "Epoch 150/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 24470.7238 - val_loss: 19617.8413\n",
      "Epoch 151/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 24235.2767 - val_loss: 20478.6877\n",
      "Epoch 152/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 23886.3026 - val_loss: 19679.8546\n",
      "Epoch 153/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 24203.4083 - val_loss: 19225.7126\n",
      "Epoch 154/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 24125.6937 - val_loss: 18712.8627\n",
      "Epoch 155/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 23699.3783 - val_loss: 19005.6716\n",
      "Epoch 156/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23628.8058 - val_loss: 20574.2034\n",
      "Epoch 157/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 23527.5995 - val_loss: 20440.9397\n",
      "Epoch 158/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 23367.5987 - val_loss: 20027.8654\n",
      "Epoch 159/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23393.3923 - val_loss: 18406.9154\n",
      "Epoch 160/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 23547.7516 - val_loss: 19510.1907\n",
      "Epoch 161/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23700.4968 - val_loss: 19711.2351\n",
      "Epoch 162/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23521.9805 - val_loss: 19353.0765\n",
      "Epoch 163/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 23289.4974 - val_loss: 18495.0024\n",
      "Epoch 164/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 23146.1177 - val_loss: 18525.8958\n",
      "Epoch 165/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 23378.2289 - val_loss: 18674.6753\n",
      "Epoch 166/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 22990.6150 - val_loss: 18405.3405\n",
      "Epoch 167/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 23208.1085 - val_loss: 18444.8079\n",
      "Epoch 168/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23341.9950 - val_loss: 18214.6930\n",
      "Epoch 169/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22968.4293 - val_loss: 18287.0789\n",
      "Epoch 170/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 23336.9285 - val_loss: 19328.6353\n",
      "Epoch 171/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23004.5811 - val_loss: 22645.0320\n",
      "Epoch 172/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 23450.7607 - val_loss: 18237.4190\n",
      "Epoch 173/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 23322.7922 - val_loss: 18528.1455\n",
      "Epoch 174/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 22646.3451 - val_loss: 18115.4026\n",
      "Epoch 175/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22568.9873 - val_loss: 19539.2561\n",
      "Epoch 176/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 23544.2008 - val_loss: 17933.2717\n",
      "Epoch 177/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22497.0116 - val_loss: 17354.5006\n",
      "Epoch 178/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22879.9811 - val_loss: 17579.1927\n",
      "Epoch 179/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22938.6665 - val_loss: 18413.8741\n",
      "Epoch 180/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22665.2603 - val_loss: 19428.7250\n",
      "Epoch 181/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22319.2484 - val_loss: 17366.1969\n",
      "Epoch 182/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22669.5232 - val_loss: 18838.8342\n",
      "Epoch 183/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22451.1597 - val_loss: 18472.8874\n",
      "Epoch 184/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22706.7617 - val_loss: 18255.4424\n",
      "Epoch 185/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22957.0078 - val_loss: 17473.3416\n",
      "Epoch 186/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22531.9464 - val_loss: 16844.6493\n",
      "Epoch 187/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 22240.5742 - val_loss: 17564.5887\n",
      "Epoch 188/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22642.6283 - val_loss: 17112.6908\n",
      "Epoch 189/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 22320.6819 - val_loss: 17639.8543\n",
      "Epoch 190/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22117.3255 - val_loss: 17005.3269\n",
      "Epoch 191/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22249.5553 - val_loss: 18395.3013\n",
      "Epoch 192/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 22401.0267 - val_loss: 16680.4410\n",
      "Epoch 193/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 22384.8159 - val_loss: 17162.2615\n",
      "Epoch 194/1000\n",
      "2304/2304 [==============================] - 1s 475us/step - loss: 21983.3552 - val_loss: 18605.2577\n",
      "Epoch 195/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22257.2526 - val_loss: 17034.5954\n",
      "Epoch 196/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 22122.9456 - val_loss: 17328.9022\n",
      "Epoch 197/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22467.4348 - val_loss: 17312.1251\n",
      "Epoch 198/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22034.0424 - val_loss: 16346.6881\n",
      "Epoch 199/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 21772.8173 - val_loss: 16449.1762\n",
      "Epoch 200/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 21616.0995 - val_loss: 19556.2224\n",
      "Epoch 201/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 22326.2749 - val_loss: 16196.6720\n",
      "Epoch 202/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22678.2432 - val_loss: 16400.9500\n",
      "Epoch 203/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 21954.1421 - val_loss: 17115.8815\n",
      "Epoch 204/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21574.3031 - val_loss: 16127.1571\n",
      "Epoch 205/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22338.9508 - val_loss: 19444.3208\n",
      "Epoch 206/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21852.7934 - val_loss: 19308.3233\n",
      "Epoch 207/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 21872.5774 - val_loss: 17685.5849\n",
      "Epoch 208/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 21486.7361 - val_loss: 16639.5072\n",
      "Epoch 209/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21571.2908 - val_loss: 16761.9651\n",
      "Epoch 210/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 21631.3609 - val_loss: 15658.4923\n",
      "Epoch 211/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21486.4054 - val_loss: 15814.1505\n",
      "Epoch 212/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21541.5087 - val_loss: 17495.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 22039.3132 - val_loss: 18907.8804\n",
      "Epoch 214/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21535.5008 - val_loss: 16334.5270\n",
      "Epoch 215/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 21397.5464 - val_loss: 15527.8804\n",
      "Epoch 216/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20970.6127 - val_loss: 15893.2644\n",
      "Epoch 217/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21382.1890 - val_loss: 16356.3695\n",
      "Epoch 218/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21161.6115 - val_loss: 17358.3467\n",
      "Epoch 219/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 21313.9134 - val_loss: 16149.4819\n",
      "Epoch 220/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21500.9419 - val_loss: 15796.3191\n",
      "Epoch 221/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 21536.2349 - val_loss: 15471.1339\n",
      "Epoch 222/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 21088.8941 - val_loss: 15343.0244\n",
      "Epoch 223/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 21667.5794 - val_loss: 17580.5199\n",
      "Epoch 224/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20965.1858 - val_loss: 15803.6322\n",
      "Epoch 225/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21442.6807 - val_loss: 17598.5028\n",
      "Epoch 226/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 21107.7338 - val_loss: 15927.4279\n",
      "Epoch 227/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20982.8748 - val_loss: 16270.2747\n",
      "Epoch 228/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21420.9400 - val_loss: 15423.4538\n",
      "Epoch 229/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 20855.8819 - val_loss: 16644.8780\n",
      "Epoch 230/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 20768.6303 - val_loss: 15575.5588\n",
      "Epoch 231/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21261.2271 - val_loss: 16437.3966\n",
      "Epoch 232/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 21497.1832 - val_loss: 15420.6945\n",
      "Epoch 233/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 20544.3840 - val_loss: 15224.6794\n",
      "Epoch 234/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21233.0104 - val_loss: 15038.2329\n",
      "Epoch 235/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21491.5446 - val_loss: 17434.5473\n",
      "Epoch 236/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21326.1712 - val_loss: 16683.8884\n",
      "Epoch 237/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 21116.4700 - val_loss: 15612.9380\n",
      "Epoch 238/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22033.4280 - val_loss: 15167.3380\n",
      "Epoch 239/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21327.5555 - val_loss: 15373.3279\n",
      "Epoch 240/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 20829.2319 - val_loss: 15861.8656\n",
      "Epoch 241/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 20925.8254 - val_loss: 15428.4299\n",
      "Epoch 242/1000\n",
      "2304/2304 [==============================] - 1s 510us/step - loss: 21137.2842 - val_loss: 19346.3964\n",
      "Epoch 243/1000\n",
      "2304/2304 [==============================] - 1s 495us/step - loss: 20912.4358 - val_loss: 15086.4801\n",
      "Epoch 244/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20783.2399 - val_loss: 17047.4020\n",
      "Epoch 245/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20600.0964 - val_loss: 16235.3380\n",
      "Epoch 246/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20756.1085 - val_loss: 15630.0819\n",
      "Epoch 247/1000\n",
      "2304/2304 [==============================] - 1s 487us/step - loss: 20794.2793 - val_loss: 15813.6791\n",
      "Epoch 248/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 20578.2091 - val_loss: 14941.2435\n",
      "Epoch 249/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20526.0308 - val_loss: 17806.7003\n",
      "Epoch 250/1000\n",
      "2304/2304 [==============================] - 1s 583us/step - loss: 20334.8256 - val_loss: 18193.9887\n",
      "Epoch 251/1000\n",
      "2304/2304 [==============================] - 1s 530us/step - loss: 20293.9275 - val_loss: 17792.9437\n",
      "Epoch 252/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20567.1465 - val_loss: 15440.0669\n",
      "Epoch 253/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20427.0153 - val_loss: 14923.4824\n",
      "Epoch 254/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20450.5625 - val_loss: 16042.9484\n",
      "Epoch 255/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 20198.3318 - val_loss: 16222.9939\n",
      "Epoch 256/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 20533.8341 - val_loss: 16831.9639\n",
      "Epoch 257/1000\n",
      "2304/2304 [==============================] - 1s 509us/step - loss: 20154.9191 - val_loss: 14754.8845\n",
      "Epoch 258/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 20387.4427 - val_loss: 15878.7856\n",
      "Epoch 259/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20359.2988 - val_loss: 16003.4819\n",
      "Epoch 260/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20531.9542 - val_loss: 16200.7362\n",
      "Epoch 261/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 20018.3629 - val_loss: 15491.6521\n",
      "Epoch 262/1000\n",
      "2304/2304 [==============================] - 1s 481us/step - loss: 20267.9428 - val_loss: 15069.8928\n",
      "Epoch 263/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 20530.1369 - val_loss: 15627.3145\n",
      "Epoch 264/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20294.7257 - val_loss: 17765.7470\n",
      "Epoch 265/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 20360.8740 - val_loss: 14508.3821\n",
      "Epoch 266/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 20267.8221 - val_loss: 15420.8517\n",
      "Epoch 267/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19862.5230 - val_loss: 14701.4737\n",
      "Epoch 268/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19815.6728 - val_loss: 14743.0286\n",
      "Epoch 269/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19757.1898 - val_loss: 16036.5053\n",
      "Epoch 270/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19572.5032 - val_loss: 15336.2828\n",
      "Epoch 271/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19700.6566 - val_loss: 15040.9445\n",
      "Epoch 272/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19473.6894 - val_loss: 15602.6384\n",
      "Epoch 273/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19906.8170 - val_loss: 14509.2126\n",
      "Epoch 274/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19699.7736 - val_loss: 15772.0936\n",
      "Epoch 275/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 20105.0729 - val_loss: 14584.7437\n",
      "Epoch 276/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20147.8612 - val_loss: 15057.5087\n",
      "Epoch 277/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19881.5120 - val_loss: 18572.5668\n",
      "Epoch 278/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19517.4842 - val_loss: 16397.4856\n",
      "Epoch 279/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19976.7596 - val_loss: 15108.0453\n",
      "Epoch 280/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19935.8306 - val_loss: 15692.7591\n",
      "Epoch 281/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19793.6322 - val_loss: 14389.2686\n",
      "Epoch 282/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19412.6952 - val_loss: 15312.0001\n",
      "Epoch 283/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20059.2136 - val_loss: 15273.2969\n",
      "Epoch 284/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19604.2384 - val_loss: 14420.2558\n",
      "Epoch 285/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19496.6790 - val_loss: 14708.9673\n",
      "Epoch 286/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 20049.3460 - val_loss: 16034.7254\n",
      "Epoch 287/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 19478.0735 - val_loss: 14571.8502\n",
      "Epoch 288/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19667.3767 - val_loss: 14611.5370\n",
      "Epoch 289/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19504.3439 - val_loss: 14015.6003\n",
      "Epoch 290/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19758.8318 - val_loss: 16997.5221\n",
      "Epoch 291/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19601.7732 - val_loss: 17615.9217\n",
      "Epoch 292/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 19661.4567 - val_loss: 16816.5259\n",
      "Epoch 293/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19131.7665 - val_loss: 14086.0776\n",
      "Epoch 294/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19576.5483 - val_loss: 14701.9938\n",
      "Epoch 295/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 19444.5205 - val_loss: 14263.2803\n",
      "Epoch 296/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 19304.4485 - val_loss: 14911.7827\n",
      "Epoch 297/1000\n",
      "2304/2304 [==============================] - 2s 687us/step - loss: 19703.8128 - val_loss: 16053.4814\n",
      "Epoch 298/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 19346.9465 - val_loss: 14261.0299\n",
      "Epoch 299/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 19704.9612 - val_loss: 14267.3405\n",
      "Epoch 300/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19352.9026 - val_loss: 14148.4302\n",
      "Epoch 301/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19498.7444 - val_loss: 14138.5259\n",
      "Epoch 302/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18726.3407 - val_loss: 15887.5956\n",
      "Epoch 303/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19946.6447 - val_loss: 16257.2649\n",
      "Epoch 304/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 19362.7704 - val_loss: 13983.4914\n",
      "Epoch 305/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 18790.8474 - val_loss: 14023.9126\n",
      "Epoch 306/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19160.9730 - val_loss: 14827.6932\n",
      "Epoch 307/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19190.6534 - val_loss: 18906.2787\n",
      "Epoch 308/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19401.0639 - val_loss: 14333.4869\n",
      "Epoch 309/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19238.1993 - val_loss: 19174.5764\n",
      "Epoch 310/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20029.8387 - val_loss: 14179.8829\n",
      "Epoch 311/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18918.1769 - val_loss: 15346.9258\n",
      "Epoch 312/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19041.3360 - val_loss: 15424.8321\n",
      "Epoch 313/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19119.5293 - val_loss: 14270.7577\n",
      "Epoch 314/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19292.8256 - val_loss: 14625.2434\n",
      "Epoch 315/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19020.3923 - val_loss: 15541.8373\n",
      "Epoch 316/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19109.0529 - val_loss: 14618.3543\n",
      "Epoch 317/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18554.5315 - val_loss: 14239.7411\n",
      "Epoch 318/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19012.3046 - val_loss: 14200.9190\n",
      "Epoch 319/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18846.4739 - val_loss: 14101.2692\n",
      "Epoch 320/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18813.7599 - val_loss: 14046.8665\n",
      "Epoch 321/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18852.2364 - val_loss: 15203.3614\n",
      "Epoch 322/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19056.3984 - val_loss: 14890.5568\n",
      "Epoch 323/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 18563.3026 - val_loss: 13836.5927\n",
      "Epoch 324/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19340.7887 - val_loss: 14266.8893\n",
      "Epoch 325/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19060.3305 - val_loss: 15360.9089\n",
      "Epoch 326/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18662.2458 - val_loss: 14017.1838\n",
      "Epoch 327/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18428.4088 - val_loss: 14745.7661\n",
      "Epoch 328/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19135.0274 - val_loss: 15207.9820\n",
      "Epoch 329/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18923.7394 - val_loss: 14965.7481\n",
      "Epoch 330/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18535.9474 - val_loss: 17499.9861\n",
      "Epoch 331/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 19013.6725 - val_loss: 15235.5978\n",
      "Epoch 332/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 18596.5386 - val_loss: 15663.1766\n",
      "Epoch 333/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18753.9279 - val_loss: 14441.8432\n",
      "Epoch 334/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18830.9042 - val_loss: 14302.3303\n",
      "Epoch 335/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18712.8998 - val_loss: 14407.8947\n",
      "Epoch 336/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18339.9842 - val_loss: 16368.5578\n",
      "Epoch 337/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 18322.5995 - val_loss: 14554.7695\n",
      "Epoch 338/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18302.4392 - val_loss: 18285.9036\n",
      "Epoch 339/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 18712.5002 - val_loss: 16307.5702\n",
      "Epoch 340/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18290.9863 - val_loss: 14239.9206\n",
      "Epoch 341/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18704.4309 - val_loss: 14550.0324\n",
      "Epoch 342/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18247.0918 - val_loss: 14879.0659\n",
      "Epoch 343/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 18006.7334 - val_loss: 18404.3097\n",
      "Epoch 344/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18743.3766 - val_loss: 14351.7088\n",
      "Epoch 345/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18354.7083 - val_loss: 13809.4760\n",
      "Epoch 346/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18344.7377 - val_loss: 14164.0234\n",
      "Epoch 347/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17953.9372 - val_loss: 15203.0973\n",
      "Epoch 348/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18169.8337 - val_loss: 15557.0146\n",
      "Epoch 349/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 18846.4769 - val_loss: 13736.5097\n",
      "Epoch 350/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 18310.2781 - val_loss: 15919.4781\n",
      "Epoch 351/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17808.3110 - val_loss: 16368.7301\n",
      "Epoch 352/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18350.3996 - val_loss: 14352.2247\n",
      "Epoch 353/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 18125.6151 - val_loss: 14588.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17982.2255 - val_loss: 15111.4960\n",
      "Epoch 355/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18200.9428 - val_loss: 16779.2044\n",
      "Epoch 356/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17829.2466 - val_loss: 15074.7010\n",
      "Epoch 357/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 18016.9196 - val_loss: 14864.5632\n",
      "Epoch 358/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17915.1799 - val_loss: 24316.4935\n",
      "Epoch 359/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19223.4313 - val_loss: 14180.9230\n",
      "Epoch 360/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 18647.8201 - val_loss: 13863.6924\n",
      "Epoch 361/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 18664.2566 - val_loss: 15385.2874\n",
      "Epoch 362/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17911.7704 - val_loss: 14680.4609\n",
      "Epoch 363/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17927.6700 - val_loss: 14011.2587\n",
      "Epoch 364/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17879.9066 - val_loss: 14464.9448\n",
      "Epoch 365/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18198.5349 - val_loss: 15854.3383\n",
      "Epoch 366/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17806.2551 - val_loss: 16639.1137\n",
      "Epoch 367/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17713.9328 - val_loss: 15978.6447\n",
      "Epoch 368/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18191.1775 - val_loss: 13860.3972\n",
      "Epoch 369/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 17839.4774 - val_loss: 16243.3496\n",
      "Epoch 370/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18056.7944 - val_loss: 13988.9696\n",
      "Epoch 371/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17830.5053 - val_loss: 13991.4631\n",
      "Epoch 372/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17826.4593 - val_loss: 14288.8727\n",
      "Epoch 373/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18230.0502 - val_loss: 13970.4442\n",
      "Epoch 374/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18149.2701 - val_loss: 13912.5779\n",
      "Epoch 375/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17991.8544 - val_loss: 14408.1569\n",
      "Epoch 376/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17852.9588 - val_loss: 13976.1019\n",
      "Epoch 377/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17220.9854 - val_loss: 14601.7443\n",
      "Epoch 378/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18052.9831 - val_loss: 14810.8670\n",
      "Epoch 379/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17936.4085 - val_loss: 15385.9314\n",
      "Epoch 380/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17604.2571 - val_loss: 22286.7142\n",
      "Epoch 381/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18617.3345 - val_loss: 16034.6185\n",
      "Epoch 382/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17403.8869 - val_loss: 14999.4376\n",
      "Epoch 383/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17939.8127 - val_loss: 14766.4007\n",
      "Epoch 384/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18240.0339 - val_loss: 14057.3904\n",
      "Epoch 385/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 17869.7416 - val_loss: 17336.3759\n",
      "Epoch 386/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17826.6345 - val_loss: 15285.4909\n",
      "Epoch 387/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17667.2922 - val_loss: 14430.3984\n",
      "Epoch 388/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17571.7256 - val_loss: 14216.6904\n",
      "Epoch 389/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17352.5210 - val_loss: 13842.0403\n",
      "Epoch 390/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17804.1591 - val_loss: 14489.6196\n",
      "Epoch 391/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17290.5272 - val_loss: 15556.0982\n",
      "Epoch 392/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17562.2438 - val_loss: 14057.2289\n",
      "Epoch 393/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17475.4925 - val_loss: 14393.1716\n",
      "Epoch 394/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 17683.2711 - val_loss: 13867.6408\n",
      "Epoch 395/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18206.1145 - val_loss: 14119.2243\n",
      "Epoch 396/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17573.8009 - val_loss: 14654.6191\n",
      "Epoch 397/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17220.1603 - val_loss: 17501.2350\n",
      "Epoch 398/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17444.1953 - val_loss: 15443.5200\n",
      "Epoch 399/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17212.9262 - val_loss: 14271.1408\n",
      "Epoch 400/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18024.3335 - val_loss: 14294.3726\n",
      "Epoch 401/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17486.2469 - val_loss: 13969.2431\n",
      "Epoch 402/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17356.3129 - val_loss: 14932.2968\n",
      "Epoch 403/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17733.6313 - val_loss: 15349.2541\n",
      "Epoch 404/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17096.2496 - val_loss: 14960.6332\n",
      "Epoch 405/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17120.7252 - val_loss: 14787.6082\n",
      "Epoch 406/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17491.6736 - val_loss: 19178.5432\n",
      "Epoch 407/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17724.7867 - val_loss: 14122.0443\n",
      "Epoch 408/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17579.8739 - val_loss: 14003.0985\n",
      "Epoch 409/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17608.8391 - val_loss: 17843.3101\n",
      "Epoch 410/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17523.1099 - val_loss: 14959.4707\n",
      "Epoch 411/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16910.8874 - val_loss: 13747.2737\n",
      "Epoch 412/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17539.3152 - val_loss: 14720.9098\n",
      "Epoch 413/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17267.5506 - val_loss: 14258.4516\n",
      "Epoch 414/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17315.9268 - val_loss: 13593.2258\n",
      "Epoch 415/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17380.5531 - val_loss: 14079.7826\n",
      "Epoch 416/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16996.8228 - val_loss: 15113.6179\n",
      "Epoch 417/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17600.8175 - val_loss: 18986.0353\n",
      "Epoch 418/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17023.1818 - val_loss: 14341.5397\n",
      "Epoch 419/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17573.1886 - val_loss: 14370.9430\n",
      "Epoch 420/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17225.8739 - val_loss: 15407.3638\n",
      "Epoch 421/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17412.0493 - val_loss: 19036.0672\n",
      "Epoch 422/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17108.0607 - val_loss: 15606.9727\n",
      "Epoch 423/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17136.4948 - val_loss: 15391.9444\n",
      "Epoch 424/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17093.5108 - val_loss: 14448.2228\n",
      "Epoch 425/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16837.8037 - val_loss: 16118.2474\n",
      "Epoch 426/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17296.2004 - val_loss: 13944.9400\n",
      "Epoch 427/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17272.2626 - val_loss: 13772.1651\n",
      "Epoch 428/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17281.5558 - val_loss: 13642.4159\n",
      "Epoch 429/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17101.2987 - val_loss: 15898.3358\n",
      "Epoch 430/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16709.3143 - val_loss: 19334.2600\n",
      "Epoch 431/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 16868.6854 - val_loss: 16250.8959\n",
      "Epoch 432/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17385.3112 - val_loss: 13705.7346\n",
      "Epoch 433/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17247.9291 - val_loss: 14623.1077\n",
      "Epoch 434/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17188.4737 - val_loss: 13852.3366\n",
      "Epoch 435/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16656.4663 - val_loss: 14797.9058\n",
      "Epoch 436/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17156.8052 - val_loss: 13735.2475\n",
      "Epoch 437/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 17050.5127 - val_loss: 17040.0685\n",
      "Epoch 438/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16785.3803 - val_loss: 15292.6484\n",
      "Epoch 439/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16491.9697 - val_loss: 15786.6080\n",
      "Epoch 440/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17464.6337 - val_loss: 15852.0196\n",
      "Epoch 441/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17213.6505 - val_loss: 15082.6042\n",
      "Epoch 442/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17345.8611 - val_loss: 14912.8041\n",
      "Epoch 443/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16981.0900 - val_loss: 18065.5751\n",
      "Epoch 444/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17532.0109 - val_loss: 16386.4432\n",
      "Epoch 445/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17591.5213 - val_loss: 14487.9600\n",
      "Epoch 446/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17624.2621 - val_loss: 16752.8077\n",
      "Epoch 447/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16998.9168 - val_loss: 13496.9836\n",
      "Epoch 448/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 16836.7056 - val_loss: 14631.2539\n",
      "Epoch 449/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16696.3389 - val_loss: 16631.2494\n",
      "Epoch 450/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16983.9090 - val_loss: 15312.0523\n",
      "Epoch 451/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16810.2610 - val_loss: 14278.9533\n",
      "Epoch 452/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17404.3263 - val_loss: 15086.4043\n",
      "Epoch 453/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17100.2959 - val_loss: 13936.6329\n",
      "Epoch 454/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16667.1507 - val_loss: 18293.9448\n",
      "Epoch 455/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17168.9288- ETA: 0s - - 1s 438us/step - loss: 17086.7000 - val_loss: 13579.2260\n",
      "Epoch 456/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16701.5239 - val_loss: 14569.9128\n",
      "Epoch 457/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16879.7268 - val_loss: 13863.3398\n",
      "Epoch 458/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16426.4349 - val_loss: 17490.6424\n",
      "Epoch 459/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 17047.0664 - val_loss: 14906.5276\n",
      "Epoch 460/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17470.8861 - val_loss: 14052.3652\n",
      "Epoch 461/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16674.0154 - val_loss: 17727.5517\n",
      "Epoch 462/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17145.5984 - val_loss: 14692.3786\n",
      "Epoch 463/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17166.9755 - val_loss: 14124.9136\n",
      "Epoch 464/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16679.6169 - val_loss: 19373.4150\n",
      "Epoch 465/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16774.5541 - val_loss: 14200.0199\n",
      "Epoch 466/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16595.9005 - val_loss: 14423.6457\n",
      "Epoch 467/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16689.2204 - val_loss: 14240.4985\n",
      "Epoch 468/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16708.0954 - val_loss: 14334.9017\n",
      "Epoch 469/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17191.4972 - val_loss: 13775.6621\n",
      "Epoch 470/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17505.5673 - val_loss: 13765.9852\n",
      "Epoch 471/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 17377.3753 - val_loss: 16874.4895\n",
      "Epoch 472/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16932.0075 - val_loss: 15280.1072\n",
      "Epoch 473/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16530.4014 - val_loss: 14520.9200\n",
      "Epoch 474/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17395.5364 - val_loss: 13848.9501\n",
      "Epoch 475/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16857.5059 - val_loss: 13565.6380\n",
      "Epoch 476/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 16767.7075 - val_loss: 19872.7868\n",
      "Epoch 477/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16884.9123 - val_loss: 13176.7210\n",
      "Epoch 478/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16330.7191 - val_loss: 14813.3151\n",
      "Epoch 479/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 16560.1846 - val_loss: 13560.4959\n",
      "Epoch 480/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16994.8374 - val_loss: 13748.0220\n",
      "Epoch 481/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 17105.0768 - val_loss: 13977.5572\n",
      "Epoch 482/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 16926.7186 - val_loss: 15421.4735\n",
      "Epoch 483/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17416.383 - 1s 442us/step - loss: 17520.7117 - val_loss: 14974.8713\n",
      "Epoch 484/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17241.7099 - val_loss: 16109.2987\n",
      "Epoch 485/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 16878.6128 - val_loss: 13340.2037\n",
      "Epoch 486/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 16567.2597 - val_loss: 13226.7989\n",
      "Epoch 487/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17009.0485 - val_loss: 14334.8273\n",
      "Epoch 488/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17224.3196 - val_loss: 15182.8221\n",
      "Epoch 489/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16113.3428 - val_loss: 14707.3002\n",
      "Epoch 490/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16157.4614 - val_loss: 17262.7748\n",
      "Epoch 491/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16754.3682 - val_loss: 17514.4146\n",
      "Epoch 492/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16435.4573 - val_loss: 13711.0666\n",
      "Epoch 493/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17039.9159 - val_loss: 15920.7148\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 443us/step - loss: 16618.5890 - val_loss: 13543.7893\n",
      "Epoch 495/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17146.2448 - val_loss: 18693.5495\n",
      "Epoch 496/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16916.5060 - val_loss: 13491.6188\n",
      "Epoch 497/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16322.7569 - val_loss: 14055.7516\n",
      "Epoch 498/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16738.7356 - val_loss: 13729.1235\n",
      "Epoch 499/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17037.1458 - val_loss: 19032.3017\n",
      "Epoch 500/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17037.1399 - val_loss: 13309.6670\n",
      "Epoch 501/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16405.3647 - val_loss: 13464.1638\n",
      "Epoch 502/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17211.2725 - val_loss: 17083.4213\n",
      "Epoch 503/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17172.4802 - val_loss: 13478.5523\n",
      "Epoch 504/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16247.5303 - val_loss: 14198.8873\n",
      "Epoch 505/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16671.5918 - val_loss: 13535.8521\n",
      "Epoch 506/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16185.6086 - val_loss: 14095.6265\n",
      "Epoch 507/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16207.7347 - val_loss: 14325.4418\n",
      "Epoch 508/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16652.1647 - val_loss: 14851.3673\n",
      "Epoch 509/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 16606.8829 - val_loss: 14483.6561\n",
      "Epoch 510/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16154.6917 - val_loss: 13027.8321\n",
      "Epoch 511/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 16352.7531 - val_loss: 13074.6578\n",
      "Epoch 512/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16269.5398 - val_loss: 15614.6946\n",
      "Epoch 513/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16844.1695 - val_loss: 13532.4958\n",
      "Epoch 514/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16391.5720 - val_loss: 13839.0900\n",
      "Epoch 515/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16910.4774 - val_loss: 13006.5320\n",
      "Epoch 516/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16441.9044 - val_loss: 13741.3823\n",
      "Epoch 517/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16175.2031 - val_loss: 13118.6830\n",
      "Epoch 518/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16029.5415 - val_loss: 13535.7123\n",
      "Epoch 519/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16822.5800 - val_loss: 12918.1999\n",
      "Epoch 520/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16400.1417 - val_loss: 13436.6186\n",
      "Epoch 521/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 16581.6498 - val_loss: 13149.8857\n",
      "Epoch 522/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16398.8991 - val_loss: 13370.1782\n",
      "Epoch 523/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16296.1482 - val_loss: 16340.5884\n",
      "Epoch 524/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16327.9647 - val_loss: 13298.2406\n",
      "Epoch 525/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16280.1426 - val_loss: 13291.0479\n",
      "Epoch 526/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16098.8848 - val_loss: 13626.7445\n",
      "Epoch 527/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16265.7438 - val_loss: 13826.5380\n",
      "Epoch 528/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15989.9011 - val_loss: 14713.3395\n",
      "Epoch 529/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15569.1148 - val_loss: 13209.5831\n",
      "Epoch 530/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16541.1532 - val_loss: 17341.2461\n",
      "Epoch 531/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16239.2389 - val_loss: 13829.2114\n",
      "Epoch 532/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16521.4224 - val_loss: 15856.1819\n",
      "Epoch 533/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15968.5748 - val_loss: 12955.7784\n",
      "Epoch 534/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16293.7703 - val_loss: 13159.6920\n",
      "Epoch 535/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15915.4719 - val_loss: 15236.5337\n",
      "Epoch 536/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16546.5183 - val_loss: 16853.1425\n",
      "Epoch 537/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16415.3709 - val_loss: 22590.1958\n",
      "Epoch 538/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16038.1731 - val_loss: 15478.0320\n",
      "Epoch 539/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16662.2867 - val_loss: 13633.4050\n",
      "Epoch 540/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16813.9251 - val_loss: 12660.4432\n",
      "Epoch 541/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16527.9992 - val_loss: 14913.9604\n",
      "Epoch 542/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 16079.3291 - val_loss: 13788.1918\n",
      "Epoch 543/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16225.2902 - val_loss: 14426.3797\n",
      "Epoch 544/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15732.6024 - val_loss: 13636.5850\n",
      "Epoch 545/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16214.2543 - val_loss: 21259.3888\n",
      "Epoch 546/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16336.5275 - val_loss: 13642.9841\n",
      "Epoch 547/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16242.7494 - val_loss: 12891.3443\n",
      "Epoch 548/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15609.3064 - val_loss: 15241.3289\n",
      "Epoch 549/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 16055.6001 - val_loss: 15129.6870\n",
      "Epoch 550/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 16056.1482 - val_loss: 13194.1173\n",
      "Epoch 551/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16373.1419 - val_loss: 13835.9007\n",
      "Epoch 552/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 16585.9757 - val_loss: 15642.5804\n",
      "Epoch 553/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16268.6899 - val_loss: 12619.5854\n",
      "Epoch 554/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16432.3227 - val_loss: 14910.7167\n",
      "Epoch 555/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15964.3666 - val_loss: 13346.9381\n",
      "Epoch 556/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15907.5030 - val_loss: 12983.0486\n",
      "Epoch 557/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15918.8584 - val_loss: 13650.5844\n",
      "Epoch 558/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16200.4612 - val_loss: 12951.2539\n",
      "Epoch 559/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15835.6661 - val_loss: 14813.2323\n",
      "Epoch 560/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16570.0578 - val_loss: 14454.0631\n",
      "Epoch 561/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16869.6169 - val_loss: 13610.7718\n",
      "Epoch 562/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16840.4261 - val_loss: 13181.9136\n",
      "Epoch 563/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15979.8033 - val_loss: 13446.4118\n",
      "Epoch 564/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15563.6671 - val_loss: 13199.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15908.4225 - val_loss: 15984.1726\n",
      "Epoch 566/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16004.9399 - val_loss: 13905.7834\n",
      "Epoch 567/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16389.2974 - val_loss: 13452.7645\n",
      "Epoch 568/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15584.9971 - val_loss: 14775.5267\n",
      "Epoch 569/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15664.2811 - val_loss: 13648.0294\n",
      "Epoch 570/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16375.2549 - val_loss: 13240.0203\n",
      "Epoch 571/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15903.5278 - val_loss: 14575.3229\n",
      "Epoch 572/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16540.2915 - val_loss: 12986.2193\n",
      "Epoch 573/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15546.8738 - val_loss: 12724.5387\n",
      "Epoch 574/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15573.6981 - val_loss: 14370.9492\n",
      "Epoch 575/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15998.9777 - val_loss: 14381.9216\n",
      "Epoch 576/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16236.6067 - val_loss: 13139.3926\n",
      "Epoch 577/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16401.3169 - val_loss: 12909.4291\n",
      "Epoch 578/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15951.6085 - val_loss: 13372.4539\n",
      "Epoch 579/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15390.301 - 1s 447us/step - loss: 15447.2109 - val_loss: 16080.7027\n",
      "Epoch 580/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15932.6666 - val_loss: 13824.2292\n",
      "Epoch 581/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15664.1162 - val_loss: 14778.0713\n",
      "Epoch 582/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15933.7029 - val_loss: 13003.9517\n",
      "Epoch 583/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15956.3189 - val_loss: 16177.6614\n",
      "Epoch 584/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15874.3583 - val_loss: 13080.2921\n",
      "Epoch 585/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16791.4277 - val_loss: 14088.6852\n",
      "Epoch 586/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15705.0799 - val_loss: 18454.0310\n",
      "Epoch 587/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15808.1309 - val_loss: 16820.5833\n",
      "Epoch 588/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16183.8922 - val_loss: 14711.2256\n",
      "Epoch 589/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15707.8248 - val_loss: 13111.5689\n",
      "Epoch 590/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16598.3475 - val_loss: 15295.8216\n",
      "Epoch 591/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15327.5790 - val_loss: 13901.1989\n",
      "Epoch 592/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15704.7646 - val_loss: 13032.4837\n",
      "Epoch 593/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15951.6286 - val_loss: 13004.5162\n",
      "Epoch 594/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15690.0711 - val_loss: 12766.9858\n",
      "Epoch 595/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15764.8322 - val_loss: 14098.1799\n",
      "Epoch 596/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16039.9761 - val_loss: 14123.3657\n",
      "Epoch 597/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16197.0552 - val_loss: 13257.4783\n",
      "Epoch 598/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15653.8917 - val_loss: 13044.1128\n",
      "Epoch 599/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 16027.9724 - val_loss: 14400.0111\n",
      "Epoch 600/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 15569.4053 - val_loss: 14585.1445\n",
      "Epoch 601/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16236.5629 - val_loss: 14213.7991\n",
      "Epoch 602/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15410.8726 - val_loss: 13744.9428\n",
      "Epoch 603/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15623.0107 - val_loss: 13769.4555\n",
      "Epoch 604/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15422.4580 - val_loss: 13720.9273\n",
      "Epoch 605/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15629.3536 - val_loss: 13780.4440\n",
      "Epoch 606/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15512.328 - 1s 449us/step - loss: 15667.5894 - val_loss: 15107.2038\n",
      "Epoch 607/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15842.8541 - val_loss: 15396.6564\n",
      "Epoch 608/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16343.3226 - val_loss: 16418.3831\n",
      "Epoch 609/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15627.2895 - val_loss: 13080.5057\n",
      "Epoch 610/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 16138.2899 - val_loss: 13839.8605\n",
      "Epoch 611/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15795.7646 - val_loss: 14323.5030\n",
      "Epoch 612/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16000.4406 - val_loss: 14379.4820\n",
      "Epoch 613/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15908.1178 - val_loss: 12850.5682\n",
      "Epoch 614/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16145.5608 - val_loss: 13584.1879\n",
      "Epoch 615/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15431.5824 - val_loss: 13392.1331\n",
      "Epoch 616/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16703.4658 - val_loss: 14792.3624\n",
      "Epoch 617/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15772.0554 - val_loss: 15436.8464\n",
      "Epoch 618/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15374.9280 - val_loss: 13229.2396\n",
      "Epoch 619/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15145.3295 - val_loss: 14809.5443\n",
      "Epoch 620/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15543.2908 - val_loss: 16547.6276\n",
      "Epoch 621/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15959.9643 - val_loss: 16376.9515\n",
      "Epoch 622/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15781.9054 - val_loss: 15017.2809\n",
      "Epoch 623/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15574.1608 - val_loss: 12977.8039\n",
      "Epoch 624/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15664.0746 - val_loss: 16512.8301\n",
      "Epoch 625/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15434.6600 - val_loss: 13110.2442\n",
      "Epoch 626/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15833.0265 - val_loss: 13771.7392\n",
      "Epoch 627/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15141.2832 - val_loss: 12895.8720\n",
      "Epoch 628/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15806.2560 - val_loss: 12599.8844\n",
      "Epoch 629/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15253.5951 - val_loss: 15702.9138\n",
      "Epoch 630/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 16220.005 - 1s 446us/step - loss: 16211.7160 - val_loss: 13587.7423\n",
      "Epoch 631/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15374.0106 - val_loss: 16109.5302\n",
      "Epoch 632/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15973.8315 - val_loss: 14559.4370\n",
      "Epoch 633/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15757.8239 - val_loss: 14605.0098\n",
      "Epoch 634/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15382.4610 - val_loss: 15446.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15981.6069 - val_loss: 14574.5966\n",
      "Epoch 636/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15255.1359 - val_loss: 16051.3238\n",
      "Epoch 637/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15448.6940 - val_loss: 13010.1859\n",
      "Epoch 638/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15537.2544 - val_loss: 14263.5028\n",
      "Epoch 639/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15717.0864 - val_loss: 13682.7131\n",
      "Epoch 640/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15358.8598 - val_loss: 13410.3975\n",
      "Epoch 641/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15642.4729 - val_loss: 13778.9329\n",
      "Epoch 642/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16350.4903 - val_loss: 21586.3186\n",
      "Epoch 643/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15697.2444 - val_loss: 13705.7611\n",
      "Epoch 644/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15046.5153 - val_loss: 16719.6757\n",
      "Epoch 645/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15784.5210 - val_loss: 13796.9106\n",
      "Epoch 646/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15669.4205 - val_loss: 12644.5263\n",
      "Epoch 647/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15642.5598 - val_loss: 13163.1053\n",
      "Epoch 648/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15469.4455 - val_loss: 14157.4993\n",
      "Epoch 649/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15148.3762 - val_loss: 12870.2361\n",
      "Epoch 650/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15614.2960 - val_loss: 12830.4788\n",
      "Epoch 651/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15455.5890 - val_loss: 14309.9376\n",
      "Epoch 652/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15504.0487 - val_loss: 12620.4909\n",
      "Epoch 653/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15521.0770 - val_loss: 13617.4397\n",
      "Epoch 654/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15487.8799 - val_loss: 13259.1685\n",
      "Epoch 655/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15204.8147 - val_loss: 13958.5722\n",
      "Epoch 656/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15702.2916 - val_loss: 13165.9372\n",
      "Epoch 657/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15200.5446 - val_loss: 14146.9903\n",
      "Epoch 658/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 15479.8287 - val_loss: 13355.3974\n",
      "Epoch 659/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15440.6843 - val_loss: 13331.1294\n",
      "Epoch 660/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15174.4019 - val_loss: 12858.8573\n",
      "Epoch 661/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15110.9219 - val_loss: 12799.9921\n",
      "Epoch 662/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15598.324 - 1s 448us/step - loss: 15515.2419 - val_loss: 12942.6975\n",
      "Epoch 663/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16275.1000 - val_loss: 16717.4047\n",
      "Epoch 664/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16169.6125 - val_loss: 12684.8459\n",
      "Epoch 665/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15119.5771 - val_loss: 17778.7259\n",
      "Epoch 666/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15477.4023 - val_loss: 13685.2982\n",
      "Epoch 667/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15982.5753 - val_loss: 14503.3253\n",
      "Epoch 668/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15682.8486 - val_loss: 15272.2460\n",
      "Epoch 669/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15223.0342 - val_loss: 12861.6631\n",
      "Epoch 670/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 15199.3037 - val_loss: 12720.9584\n",
      "Epoch 671/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15367.5364 - val_loss: 12661.7466\n",
      "Epoch 672/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15171.9637 - val_loss: 13398.3861\n",
      "Epoch 673/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15272.5848 - val_loss: 13891.8174\n",
      "Epoch 674/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15364.4168 - val_loss: 13129.6698\n",
      "Epoch 675/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15352.5513 - val_loss: 13137.0173\n",
      "Epoch 676/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15420.8494 - val_loss: 14306.8728\n",
      "Epoch 677/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15816.9606 - val_loss: 13225.2205\n",
      "Epoch 678/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15520.9441 - val_loss: 12961.2857\n",
      "Epoch 679/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16166.1388 - val_loss: 13093.5504\n",
      "Epoch 680/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15809.7020 - val_loss: 12755.8231\n",
      "Epoch 681/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15275.4096 - val_loss: 14574.4372\n",
      "Epoch 682/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15262.1467 - val_loss: 15008.6220\n",
      "Epoch 683/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15541.8515 - val_loss: 12507.0198\n",
      "Epoch 684/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15458.2967 - val_loss: 12919.8445\n",
      "Epoch 685/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15089.8102 - val_loss: 13483.9403\n",
      "Epoch 686/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15078.7916 - val_loss: 13308.9251\n",
      "Epoch 687/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14969.1277 - val_loss: 15465.7025\n",
      "Epoch 688/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15335.7592 - val_loss: 12952.5697\n",
      "Epoch 689/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15527.9751 - val_loss: 17052.4783\n",
      "Epoch 690/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15339.5878 - val_loss: 14415.3618\n",
      "Epoch 691/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15469.8665 - val_loss: 14247.9914\n",
      "Epoch 692/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15702.3830 - val_loss: 17907.0751\n",
      "Epoch 693/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15765.4085 - val_loss: 13254.7512\n",
      "Epoch 694/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15332.0656 - val_loss: 18456.6299\n",
      "Epoch 695/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15447.8551 - val_loss: 12613.2257\n",
      "Epoch 696/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14687.8422 - val_loss: 13083.2457\n",
      "Epoch 697/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15330.3883 - val_loss: 18014.6404\n",
      "Epoch 698/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15781.9598 - val_loss: 16162.5326\n",
      "Epoch 699/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15493.8309 - val_loss: 17285.5977\n",
      "Epoch 700/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15423.0763 - val_loss: 12625.9207\n",
      "Epoch 701/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15297.0811 - val_loss: 13373.4003\n",
      "Epoch 702/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15426.0078 - val_loss: 13488.4394\n",
      "Epoch 703/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15466.9557 - val_loss: 14845.1572\n",
      "Epoch 704/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15065.8811 - val_loss: 12732.2395\n",
      "Epoch 705/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15026.7516 - val_loss: 13223.4333\n",
      "Epoch 706/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15230.2854 - val_loss: 14756.2749\n",
      "Epoch 707/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15406.9381 - val_loss: 13308.5025\n",
      "Epoch 708/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15260.3629 - val_loss: 18116.0258\n",
      "Epoch 709/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15283.3038 - val_loss: 13337.3922\n",
      "Epoch 710/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15137.5314 - val_loss: 13265.3038\n",
      "Epoch 711/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15759.4561 - val_loss: 14528.8233\n",
      "Epoch 712/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15241.5850 - val_loss: 12762.3783\n",
      "Epoch 713/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14968.4679 - val_loss: 13901.8424\n",
      "Epoch 714/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15471.8470 - val_loss: 13121.6925\n",
      "Epoch 715/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15340.8782 - val_loss: 16421.3447\n",
      "Epoch 716/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15203.0577 - val_loss: 13425.4123\n",
      "Epoch 717/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15364.1613 - val_loss: 14678.5288\n",
      "Epoch 718/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15190.8276 - val_loss: 13293.1317\n",
      "Epoch 719/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15485.2657 - val_loss: 16684.7799\n",
      "Epoch 720/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16062.7201 - val_loss: 12756.5438\n",
      "Epoch 721/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15582.1366 - val_loss: 13934.6589\n",
      "Epoch 722/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14930.4560 - val_loss: 14532.9120\n",
      "Epoch 723/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15068.7575 - val_loss: 12634.7672\n",
      "Epoch 724/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15363.4014 - val_loss: 13434.6976\n",
      "Epoch 725/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15257.4327 - val_loss: 18779.9918\n",
      "Epoch 726/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15877.7786 - val_loss: 13005.0797\n",
      "Epoch 727/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15261.8529 - val_loss: 12943.7489\n",
      "Epoch 728/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15631.8654 - val_loss: 12685.7935\n",
      "Epoch 729/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15082.9631 - val_loss: 12853.9259\n",
      "Epoch 730/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14789.6620 - val_loss: 13291.1079\n",
      "Epoch 731/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14779.1322 - val_loss: 12923.7221\n",
      "Epoch 732/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14957.5461 - val_loss: 14639.1517\n",
      "Epoch 733/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15424.5130 - val_loss: 12906.5334\n",
      "Epoch 734/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15092.7149 - val_loss: 12938.7308\n",
      "Epoch 735/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14993.9403 - val_loss: 13545.9049\n",
      "Epoch 736/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14567.7017 - val_loss: 13553.1889\n",
      "Epoch 737/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 15193.0467 - val_loss: 16555.1944\n",
      "Epoch 738/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15208.2199 - val_loss: 13473.8713\n",
      "Epoch 739/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15558.0719 - val_loss: 13306.9156\n",
      "Epoch 740/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15205.8590 - val_loss: 13603.1274\n",
      "Epoch 741/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14711.1822 - val_loss: 17975.5598\n",
      "Epoch 742/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15439.0352 - val_loss: 18252.7317\n",
      "Epoch 743/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14858.0257 - val_loss: 13080.7335\n",
      "Epoch 744/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15334.4735 - val_loss: 12367.6314\n",
      "Epoch 745/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15592.4208 - val_loss: 12456.6742\n",
      "Epoch 746/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15372.3296 - val_loss: 13681.8867\n",
      "Epoch 747/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15552.5056 - val_loss: 13359.9924\n",
      "Epoch 748/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15025.2245 - val_loss: 13198.7190\n",
      "Epoch 749/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15587.6711 - val_loss: 13291.3897\n",
      "Epoch 750/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15234.3599 - val_loss: 13104.8654\n",
      "Epoch 751/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15286.4515 - val_loss: 13389.0263\n",
      "Epoch 752/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15011.1919 - val_loss: 13671.0663\n",
      "Epoch 753/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14678.4676 - val_loss: 13171.7875\n",
      "Epoch 754/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14898.6622 - val_loss: 16745.6186\n",
      "Epoch 755/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14864.0150 - val_loss: 14502.9875\n",
      "Epoch 756/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14996.6706 - val_loss: 14170.1225\n",
      "Epoch 757/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14958.4556 - val_loss: 13103.1940\n",
      "Epoch 758/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14827.0645 - val_loss: 12728.4479\n",
      "Epoch 759/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15163.0861 - val_loss: 13287.7952\n",
      "Epoch 760/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14740.0526 - val_loss: 12897.9880\n",
      "Epoch 761/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14966.5553 - val_loss: 13621.3832\n",
      "Epoch 762/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14799.1578 - val_loss: 14286.3744\n",
      "Epoch 763/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14436.9415 - val_loss: 13498.1127\n",
      "Epoch 764/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15144.7726 - val_loss: 12865.2890\n",
      "Epoch 765/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15369.3907 - val_loss: 13159.7846\n",
      "Epoch 766/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14932.8306 - val_loss: 13319.9050\n",
      "Epoch 767/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14700.5915 - val_loss: 12496.0247\n",
      "Epoch 768/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14422.4766 - val_loss: 12903.3622\n",
      "Epoch 769/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 14772.8422 - val_loss: 12729.0690\n",
      "Epoch 770/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15411.607 - 1s 442us/step - loss: 15346.0232 - val_loss: 14042.6256\n",
      "Epoch 771/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15231.9011 - val_loss: 13969.7030\n",
      "Epoch 772/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15155.9134 - val_loss: 14454.8772\n",
      "Epoch 773/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15267.4308 - val_loss: 13259.2004\n",
      "Epoch 774/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14596.1594 - val_loss: 13166.8524\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 420us/step - loss: 14974.0176 - val_loss: 15539.5823\n",
      "Epoch 776/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15169.9119 - val_loss: 13228.7943\n",
      "Epoch 777/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14630.1758 - val_loss: 13663.6288\n",
      "Epoch 778/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14674.2638 - val_loss: 12558.5938\n",
      "Epoch 779/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14920.9787 - val_loss: 13532.3238\n",
      "Epoch 780/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 15182.5596 - val_loss: 15951.0021\n",
      "Epoch 781/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14665.4194 - val_loss: 12908.2029\n",
      "Epoch 782/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14690.0533 - val_loss: 14167.9302\n",
      "Epoch 783/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14653.5695 - val_loss: 17030.5262\n",
      "Epoch 784/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15122.4909 - val_loss: 12568.5641\n",
      "Epoch 785/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15265.6583 - val_loss: 12658.0560\n",
      "Epoch 786/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 14948.2878 - val_loss: 13892.8752\n",
      "Epoch 787/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14933.4436 - val_loss: 14457.1670\n",
      "Epoch 788/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15085.2040 - val_loss: 13747.4289\n",
      "Epoch 789/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15379.0492 - val_loss: 19403.6576\n",
      "Epoch 790/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 15351.0965 - val_loss: 15456.3321\n",
      "Epoch 791/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14805.4371 - val_loss: 12852.0827\n",
      "Epoch 792/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14794.1490 - val_loss: 12984.7817\n",
      "Epoch 793/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14434.4702 - val_loss: 12845.6965\n",
      "Epoch 794/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 14672.0893 - val_loss: 13594.8156\n",
      "Epoch 795/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 14665.5351 - val_loss: 13367.0068\n",
      "Epoch 796/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14691.3304 - val_loss: 12902.3428\n",
      "Epoch 797/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15322.3794 - val_loss: 13206.3453\n",
      "Epoch 798/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14591.8013 - val_loss: 12691.5457\n",
      "Epoch 799/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14238.9320 - val_loss: 12883.0565\n",
      "Epoch 800/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14562.4019 - val_loss: 13239.7346\n",
      "Epoch 801/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14895.1009 - val_loss: 12925.1134\n",
      "Epoch 802/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14640.8927 - val_loss: 12759.0829\n",
      "Epoch 803/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14646.1457 - val_loss: 12718.9311\n",
      "Epoch 804/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14635.7928 - val_loss: 12636.7899\n",
      "Epoch 805/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 13996.3517 - val_loss: 14381.3851\n",
      "Epoch 806/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14318.8125 - val_loss: 15468.8791\n",
      "Epoch 807/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14880.0421 - val_loss: 13126.8431\n",
      "Epoch 808/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15080.8034 - val_loss: 14136.3962\n",
      "Epoch 809/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15469.5417 - val_loss: 12694.9700\n",
      "Epoch 810/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14256.0116 - val_loss: 12779.1585\n",
      "Epoch 811/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15062.1193 - val_loss: 13845.3082\n",
      "Epoch 812/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14080.0018 - val_loss: 13449.0193\n",
      "Epoch 813/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14612.0249 - val_loss: 13226.6961\n",
      "Epoch 814/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14793.5876 - val_loss: 12672.4397\n",
      "Epoch 815/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14473.2528 - val_loss: 12693.7991\n",
      "Epoch 816/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14533.8183 - val_loss: 13692.2471\n",
      "Epoch 817/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14729.4543 - val_loss: 13083.3531\n",
      "Epoch 818/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14497.7936 - val_loss: 13903.4400\n",
      "Epoch 819/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14109.7411 - val_loss: 13386.7339\n",
      "Epoch 820/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14994.6687 - val_loss: 14384.5567\n",
      "Epoch 821/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14667.1439 - val_loss: 16717.5792\n",
      "Epoch 822/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 15194.1799 - val_loss: 12673.5339\n",
      "Epoch 823/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14383.1840 - val_loss: 13179.6093\n",
      "Epoch 824/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14762.0785 - val_loss: 12920.0712\n",
      "Epoch 825/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14621.4354 - val_loss: 13191.5815\n",
      "Epoch 826/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14784.9669 - val_loss: 12863.7764\n",
      "Epoch 827/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14490.9969 - val_loss: 12752.3748\n",
      "Epoch 828/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14351.1834 - val_loss: 12576.6446\n",
      "Epoch 829/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 15036.8720 - val_loss: 12418.5804\n",
      "Epoch 830/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14464.0178 - val_loss: 12871.3090\n",
      "Epoch 831/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14654.7483 - val_loss: 13201.5221\n",
      "Epoch 832/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14462.2237 - val_loss: 13925.0163\n",
      "Epoch 833/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14949.5650 - val_loss: 13039.8272\n",
      "Epoch 834/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14270.4275 - val_loss: 12572.5281\n",
      "Epoch 835/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14900.3856 - val_loss: 12620.9649\n",
      "Epoch 836/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14709.6670 - val_loss: 12989.1388\n",
      "Epoch 837/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14657.4319 - val_loss: 13228.2369\n",
      "Epoch 838/1000\n",
      "2304/2304 [==============================] - 1s 472us/step - loss: 14724.9100 - val_loss: 12757.6617\n",
      "Epoch 839/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14601.4974 - val_loss: 12417.1430\n",
      "Epoch 840/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14986.3101 - val_loss: 17222.0426\n",
      "Epoch 841/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 15089.0709 - val_loss: 12555.9500\n",
      "Epoch 842/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14993.7458 - val_loss: 14066.9829\n",
      "Epoch 843/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14532.6220 - val_loss: 18880.1531\n",
      "Epoch 844/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14584.9105 - val_loss: 13635.9832\n",
      "Epoch 845/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14396.5144 - val_loss: 12778.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14060.4311 - val_loss: 13225.5006\n",
      "Epoch 847/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14654.3758 - val_loss: 13023.3650\n",
      "Epoch 848/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14654.8375 - val_loss: 13103.5657\n",
      "Epoch 849/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14830.6239 - val_loss: 13058.2414\n",
      "Epoch 850/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14764.2105 - val_loss: 13815.4281\n",
      "Epoch 851/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14613.9552 - val_loss: 13237.9735\n",
      "Epoch 852/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14611.7756 - val_loss: 13520.5362\n",
      "Epoch 853/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14431.8364 - val_loss: 13894.3668\n",
      "Epoch 854/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15137.1521 - val_loss: 22284.5248\n",
      "Epoch 855/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14813.4715 - val_loss: 13260.7255\n",
      "Epoch 856/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14475.8784 - val_loss: 13210.7836\n",
      "Epoch 857/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 14933.4577 - val_loss: 12749.1952\n",
      "Epoch 858/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14291.2518 - val_loss: 14971.0328\n",
      "Epoch 859/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15208.3715 - val_loss: 15258.7614\n",
      "Epoch 860/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14987.8951 - val_loss: 13586.2548\n",
      "Epoch 861/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14492.0720 - val_loss: 17675.6073\n",
      "Epoch 862/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14506.5116 - val_loss: 12518.2817\n",
      "Epoch 863/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14188.5038 - val_loss: 13342.0729\n",
      "Epoch 864/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15359.8370 - val_loss: 16495.8379\n",
      "Epoch 865/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14965.1403 - val_loss: 13083.3793\n",
      "Epoch 866/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14175.7473 - val_loss: 13919.3206\n",
      "Epoch 867/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14389.9764 - val_loss: 13285.3221\n",
      "Epoch 868/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14221.4755 - val_loss: 16674.3418\n",
      "Epoch 869/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 13982.3276 - val_loss: 14725.3013\n",
      "Epoch 870/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14150.5493 - val_loss: 12991.6504\n",
      "Epoch 871/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14241.1971 - val_loss: 14242.6713\n",
      "Epoch 872/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14235.1650 - val_loss: 13106.2846\n",
      "Epoch 873/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14888.9844 - val_loss: 13805.2642\n",
      "Epoch 874/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 14627.0407 - val_loss: 13571.2920\n",
      "Epoch 875/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14100.9699 - val_loss: 13488.7944\n",
      "Epoch 876/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14497.7654 - val_loss: 12479.8602\n",
      "Epoch 877/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14594.8237 - val_loss: 12449.0825\n",
      "Epoch 878/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14203.2660 - val_loss: 12609.4652\n",
      "Epoch 879/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14727.8350 - val_loss: 12740.9682\n",
      "Epoch 880/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14200.1342 - val_loss: 12994.0223\n",
      "Epoch 881/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14441.8817 - val_loss: 16508.9571\n",
      "Epoch 882/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 14590.5564 - val_loss: 12704.1016\n",
      "Epoch 883/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14141.6053 - val_loss: 14625.2396\n",
      "Epoch 884/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14457.2792 - val_loss: 13181.9282\n",
      "Epoch 885/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 14154.0893 - val_loss: 13142.0646\n",
      "Epoch 886/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14099.0075 - val_loss: 12615.8368\n",
      "Epoch 887/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14432.0832 - val_loss: 13688.7647\n",
      "Epoch 888/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14763.6511 - val_loss: 12546.1383\n",
      "Epoch 889/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 14257.1427 - val_loss: 15314.1020\n",
      "Epoch 890/1000\n",
      "2304/2304 [==============================] - 1s 407us/step - loss: 14685.3420 - val_loss: 12802.6904\n",
      "Epoch 891/1000\n",
      "2304/2304 [==============================] - 1s 398us/step - loss: 14311.2269 - val_loss: 13009.1204\n",
      "Epoch 892/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14441.2347 - val_loss: 13246.5764\n",
      "Epoch 893/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 13962.6542 - val_loss: 13388.3987\n",
      "Epoch 894/1000\n",
      "2304/2304 [==============================] - 1s 403us/step - loss: 14644.0992 - val_loss: 16022.9132\n",
      "Epoch 895/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14487.1708 - val_loss: 13156.4069\n",
      "Epoch 896/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14494.2526 - val_loss: 12960.4321\n",
      "Epoch 897/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14206.2011 - val_loss: 13049.3552\n",
      "Epoch 898/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14461.0843 - val_loss: 13081.9360\n",
      "Epoch 899/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14231.0203 - val_loss: 12909.8227\n",
      "Epoch 900/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14248.6927 - val_loss: 15215.5780\n",
      "Epoch 901/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14475.0888 - val_loss: 12317.9968\n",
      "Epoch 902/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14409.6735 - val_loss: 12467.8517\n",
      "Epoch 903/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14274.7537 - val_loss: 13747.5079\n",
      "Epoch 904/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14452.9215 - val_loss: 12402.7182\n",
      "Epoch 905/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14406.0842 - val_loss: 13519.5157\n",
      "Epoch 906/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14147.5470 - val_loss: 15100.2449\n",
      "Epoch 907/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14430.0315 - val_loss: 13061.8966\n",
      "Epoch 908/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14037.1031 - val_loss: 15047.8518\n",
      "Epoch 909/1000\n",
      "2304/2304 [==============================] - 1s 404us/step - loss: 14497.5600 - val_loss: 12198.8537\n",
      "Epoch 910/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 14366.8323 - val_loss: 14644.8727\n",
      "Epoch 911/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14138.7617 - val_loss: 13198.3730\n",
      "Epoch 912/1000\n",
      "2304/2304 [==============================] - 1s 387us/step - loss: 14551.6633 - val_loss: 12640.6007\n",
      "Epoch 913/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 13842.8162 - val_loss: 13103.7514\n",
      "Epoch 914/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14027.096 - 1s 406us/step - loss: 14014.5653 - val_loss: 13519.0226\n",
      "Epoch 915/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14198.5005 - val_loss: 13368.7286\n",
      "Epoch 916/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14822.5560 - val_loss: 15374.5320\n",
      "Epoch 917/1000\n",
      "2304/2304 [==============================] - 1s 402us/step - loss: 14289.0921 - val_loss: 14090.4929\n",
      "Epoch 918/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 14206.7270 - val_loss: 13044.4802\n",
      "Epoch 919/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14460.7795 - val_loss: 13302.6180\n",
      "Epoch 920/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14155.9907 - val_loss: 13949.3602\n",
      "Epoch 921/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14249.6631 - val_loss: 13610.0707\n",
      "Epoch 922/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 13840.5041 - val_loss: 13909.9199\n",
      "Epoch 923/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 13814.5286 - val_loss: 12826.1274\n",
      "Epoch 924/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14904.2527 - val_loss: 13254.0662\n",
      "Epoch 925/1000\n",
      "2304/2304 [==============================] - 1s 401us/step - loss: 14411.9720 - val_loss: 12841.3170\n",
      "Epoch 926/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14629.6957 - val_loss: 15033.8485\n",
      "Epoch 927/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14348.2908 - val_loss: 14876.2320\n",
      "Epoch 928/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14075.3151 - val_loss: 13959.1821\n",
      "Epoch 929/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14288.5601 - val_loss: 12458.3268\n",
      "Epoch 930/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14819.0479 - val_loss: 12861.2873\n",
      "Epoch 931/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 13920.4318 - val_loss: 12759.2584\n",
      "Epoch 932/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14030.5567 - val_loss: 16690.3853\n",
      "Epoch 933/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14995.1577 - val_loss: 12408.4145\n",
      "Epoch 934/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14364.7210 - val_loss: 13108.9323\n",
      "Epoch 935/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14219.7713 - val_loss: 12570.9672\n",
      "Epoch 936/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14441.0540 - val_loss: 12885.1096\n",
      "Epoch 937/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14052.5804 - val_loss: 12657.4459\n",
      "Epoch 938/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 13923.9323 - val_loss: 13260.1057\n",
      "Epoch 939/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 14013.6045 - val_loss: 13729.9309\n",
      "Epoch 940/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13959.4256 - val_loss: 12934.7212\n",
      "Epoch 941/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14320.5392 - val_loss: 13995.1145\n",
      "Epoch 942/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14821.987 - 1s 402us/step - loss: 14817.3598 - val_loss: 12546.6118\n",
      "Epoch 943/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 13632.6041 - val_loss: 12900.9206\n",
      "Epoch 944/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14375.1462 - val_loss: 12765.3758\n",
      "Epoch 945/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 14128.5347 - val_loss: 14432.7357\n",
      "Epoch 946/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14197.4131 - val_loss: 13281.8154\n",
      "Epoch 947/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14080.5850 - val_loss: 12181.3528\n",
      "Epoch 948/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14324.9667 - val_loss: 12349.6915\n",
      "Epoch 949/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14012.5511 - val_loss: 13018.6412\n",
      "Epoch 950/1000\n",
      "2304/2304 [==============================] - 1s 390us/step - loss: 14255.0074 - val_loss: 15873.9080\n",
      "Epoch 951/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14717.7372 - val_loss: 12762.9510\n",
      "Epoch 952/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13974.3436 - val_loss: 12546.4765\n",
      "Epoch 953/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14234.0405 - val_loss: 13405.9529\n",
      "Epoch 954/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14021.4645 - val_loss: 12466.7760\n",
      "Epoch 955/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 13925.6977 - val_loss: 13453.8253\n",
      "Epoch 956/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14474.5282 - val_loss: 12504.4543\n",
      "Epoch 957/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 13990.5396 - val_loss: 12301.0943\n",
      "Epoch 958/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 13936.6069 - val_loss: 13217.6736\n",
      "Epoch 959/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14229.4402 - val_loss: 12295.4087\n",
      "Epoch 960/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14244.5842 - val_loss: 12878.1249\n",
      "Epoch 961/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 13966.3603 - val_loss: 13099.1012\n",
      "Epoch 962/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14448.5880 - val_loss: 13052.2593\n",
      "Epoch 963/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13804.9836 - val_loss: 13043.3453\n",
      "Epoch 964/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14432.2674 - val_loss: 12421.3675\n",
      "Epoch 965/1000\n",
      "2304/2304 [==============================] - 1s 389us/step - loss: 13866.9203 - val_loss: 12710.0364\n",
      "Epoch 966/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14118.5367 - val_loss: 12608.4325\n",
      "Epoch 967/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13863.9051 - val_loss: 12497.9934\n",
      "Epoch 968/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14055.5219 - val_loss: 12798.6343\n",
      "Epoch 969/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14203.0176 - val_loss: 12626.2237\n",
      "Epoch 970/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14280.9816 - val_loss: 12754.1671\n",
      "Epoch 971/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13951.1702 - val_loss: 12712.6477\n",
      "Epoch 972/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14304.2816 - val_loss: 17329.0146\n",
      "Epoch 973/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 15169.8071 - val_loss: 12271.1659\n",
      "Epoch 974/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14481.7509 - val_loss: 13241.9281\n",
      "Epoch 975/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13924.4217 - val_loss: 13457.2602\n",
      "Epoch 976/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14402.3264 - val_loss: 12988.4250\n",
      "Epoch 977/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13917.5887 - val_loss: 14214.5680\n",
      "Epoch 978/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13851.6644 - val_loss: 14613.6863\n",
      "Epoch 979/1000\n",
      "2304/2304 [==============================] - 1s 375us/step - loss: 13638.6078 - val_loss: 12895.8128\n",
      "Epoch 980/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14048.2012 - val_loss: 15794.4410\n",
      "Epoch 981/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14248.7375 - val_loss: 12595.4897\n",
      "Epoch 982/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 13976.9222 - val_loss: 12944.9743\n",
      "Epoch 983/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 13878.1132 - val_loss: 14461.1452\n",
      "Epoch 984/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13750.8418 - val_loss: 13647.0555\n",
      "Epoch 985/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13821.2843 - val_loss: 15657.8466\n",
      "Epoch 986/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 387us/step - loss: 13951.3668 - val_loss: 12503.4262\n",
      "Epoch 987/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13732.6873 - val_loss: 12674.2793\n",
      "Epoch 988/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14143.0375 - val_loss: 12801.1951\n",
      "Epoch 989/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14586.6882 - val_loss: 13891.1528\n",
      "Epoch 990/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14043.9540 - val_loss: 12848.9969\n",
      "Epoch 991/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14709.4745 - val_loss: 13196.8980\n",
      "Epoch 992/1000\n",
      "2304/2304 [==============================] - 1s 379us/step - loss: 13989.1206 - val_loss: 13358.9111\n",
      "Epoch 993/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13895.6108 - val_loss: 12177.6148\n",
      "Epoch 994/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13983.3783 - val_loss: 12892.7427\n",
      "Epoch 995/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14490.0895 - val_loss: 14749.1190\n",
      "Epoch 996/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14125.6700 - val_loss: 13738.9878\n",
      "Epoch 997/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 14066.8977 - val_loss: 12453.9828\n",
      "Epoch 998/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 13551.5174 - val_loss: 14619.2152\n",
      "Epoch 999/1000\n",
      "2304/2304 [==============================] - 1s 386us/step - loss: 13681.4783 - val_loss: 12727.4434\n",
      "Epoch 1000/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14083.6308 - val_loss: 13065.0160\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
